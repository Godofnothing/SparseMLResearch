training_modifiers:
  
  - !EpochRangeModifier
    start_epoch: 0
    end_epoch: 301
  
  - !SetLearningRateModifier
    constant_logging: False
    start_epoch: 0
    end_epoch: 201
    learning_rate: 0.0001
    log_types: __ALL__

  - !LearningRateFunctionModifier
    start_epoch: 201
    end_epoch: 301
    lr_func: cosine
    init_lr: 0.0001
    final_lr: 0.000001
  
pruning_modifiers:

  - !MFACPruningModifier
      init_sparsity: 0.0
      final_sparsity: 0.75
      start_epoch: 1
      end_epoch: 201    
      update_frequency: 5
      params: ['re:(.*blocks.*.attn.qkv.weight)|(.*blocks.*.attn.proj.weight)|(.*blocks.*.mlp.fc.*weight)'] 
      global_sparsity : True
      num_grads: 256
      fisher_block_size: 64
      damp: 0.0000001
      grads_device: cuda

  - !MFACPruningModifier
      init_sparsity: 0.75
      final_sparsity: 0.75
      start_epoch: 201
      end_epoch: 301  
      update_frequency: 100
      params: ['re:(.*blocks.*.attn.qkv.weight)|(.*blocks.*.attn.proj.weight)|(.*blocks.*.mlp.fc.*weight)'] 
      global_sparsity : True
      num_grads: 256
      fisher_block_size: 64
      damp: 0.0000001
      grads_device: cuda